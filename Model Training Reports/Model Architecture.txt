##############################################
 PPO CNN Policy Architecture Documentation
##############################################

## Overview
This document provides a detailed breakdown of the Actor-Critic CNN policy architecture used in Stable-Baselines3's PPO for training an agent in the CarRacing-v2 environment. The model is implemented using the ActorCriticCnnPolicy, which consists of three CNN feature extractors and fully connected layers for decision-making.

----------------------------------------------------
 Model Structure
----------------------------------------------------

The model follows an Actor-Critic architecture with separate networks for the policy (actor) and value function (critic).

### 1. Feature Extraction (Convolutional Layers)
Each feature extractor follows the NatureCNN architecture, consisting of three convolutional layers followed by a fully connected layer. The CNN is applied to grayscale or RGB images (3-channel input).

#### CNN Layers:
- Conv Layer 1:
  - Input channels: 3
  - Output channels: 32
  - Kernel size: (8,8)
  - Stride: 4
  - Activation: ReLU
  - Parameters: (3 × 8 × 8 + 1) × 32 = 6,176

- Conv Layer 2:
  - Input channels: 32
  - Output channels: 64
  - Kernel size: (4,4)
  - Stride: 2
  - Activation: ReLU
  - Parameters: (32 × 4 × 4 + 1) × 64 = 32,832

- Conv Layer 3:
  - Input channels: 64
  - Output channels: 64
  - Kernel size: (3,3)
  - Stride: 1
  - Activation: ReLU
  - Parameters: (64 × 3 × 3 + 1) × 64 = 36,928

- Flatten Layer (Flattens the CNN output to a vector of size 4096)

- Fully Connected Layer (FC1):
  - Input size: 4096
  - Output size: 512
  - Activation: ReLU
  - Parameters: (4096 + 1) × 512 = 2,097,152

- Total Parameters per CNN Feature Extractor: 2,173,088
- Number of Feature Extractors: 3
- Total Feature Extractor Parameters: 2,173,088 × 3 = 6,519,264

### 2. Action & Value Networks (MLP Layers)
After feature extraction, the extracted feature vector (512-dimensional) is passed to the policy (actor) and value (critic) networks.

#### Policy Network (Actor):
- Linear Layer:
  - Input size: 512
  - Output size: 3 (for 3 possible actions)
  - Parameters: (512 + 1) × 3 = 1,539

#### Value Network (Critic):
- Linear Layer:
  - Input size: 512
  - Output size: 1
  - Parameters: (512 + 1) × 1 = 513

### 3. Final Model Parameter Count
| Component                    | Parameters  |
|------------------------------|------------|
| CNN Feature Extractors (3x)  | 6,519,264  |
| Policy Network (Actor)       | 1,539      |
| Value Network (Critic)       | 513        |
| Total Trainable Parameters | 6,521,316 |

----------------------------------------------------
 Summary of Architecture
----------------------------------------------------
- Policy: CNN extracts features → Fully connected layer → Action output (Actor)
- Value Function: CNN extracts features → Fully connected layer → Single scalar output (Critic)
- Gradient Updates: Performed using PPO's clipped surrogate loss via backpropagation.
- Shared vs. Separate Extractors: This implementation uses three separate CNNs for generalization.
- Potential Optimization: Feature extractors could be shared to reduce parameters from 6.5M to 2.1M.

----------------------------------------------------
 Conclusion
----------------------------------------------------
This model is highly parameter-intensive due to three separate CNN feature extractors. Understanding its structure allows for better debugging, fine-tuning, and potential optimizations. Consider weight sharing between the actor and critic for reducing computational cost if performance is acceptable.

For visualizing the architecture in Python, use:
```python
import torch
from stable_baselines3 import PPO

model = PPO.load("your_model_path.zip")
print(model.policy)
